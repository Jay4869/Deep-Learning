{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform\n",
    "import time\n",
    "from Model import Residual_Unit\n",
    "from Model import Attention_Block\n",
    "from Model import AttentionResNet56_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.0.0\n",
      "Keras version: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "print(\"TF version: \",tf.__version__)\n",
    "print(\"Keras version:\",tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping,TensorBoard\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cifar10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR10 data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input image shape: (32, 32, 3)\n",
      "x_train shape: (5000, 32, 32, 3)\n",
      "y_train shape: (5000, 1)\n",
      "x_test shape: (1000, 32, 32, 3)\n",
      "y_test shape: (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train[:5000, :, :, :]\n",
    "y_train = y_train[:5000]\n",
    "x_test = x_test[:1000, :, :, :]\n",
    "y_test = y_test[:1000]\n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "print('input image shape:', input_shape)\n",
    "\n",
    "# # resize image\n",
    "# start = time.time()\n",
    "\n",
    "# temp = []\n",
    "# for i in range(1000):\n",
    "#     temp.append(skimage.transform.resize(x_train[i,:,:,:], (224, 224), mode='constant'))\n",
    "    \n",
    "# x_train = np.array(temp).reshape((-1, 224, 224, 3))\n",
    "    \n",
    "# temp = []\n",
    "# for i in range(200):\n",
    "#     temp.append(skimage.transform.resize(x_test[i,:,:,:], (224, 224), mode='constant'))\n",
    "    \n",
    "# x_test = np.array(temp).reshape((-1, 224, 224, 3))\n",
    "\n",
    "# end = time.time()\n",
    "# print(\"Time taken by above cell is {}.\".format((end-start)/60))\n",
    "    \n",
    "# # Preprocessing: subtract the mean value across every dimension for training data\n",
    "# mean_image = np.mean(x_train, axis=0)\n",
    "# mean_image_test = np.mean(x_test, axis=0)\n",
    "\n",
    "# x_train = x_train.astype('float32') - mean_image.astype('float32')\n",
    "# x_test = x_test.astype('float32') - mean_image_test\n",
    "\n",
    "# x_train = x_train / 255\n",
    "# x_test = x_test / 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(2,2))\n",
    "\n",
    "plt.imshow(x_train[20,:,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generators for training and validation data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "train_datagen.fit(x_train)\n",
    "val_datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 32)   2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 16, 16, 32)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 32)   128         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16, 16, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 32)   1056        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16, 16, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 32)   9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16, 16, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 128)  4224        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 128)  4224        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 16, 16, 128)  0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 128)  512         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   4128        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 32)   9248        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 128)  4224        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 128)  16512       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 16, 128)  0           conv2d_7[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 128)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 128)    512         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 32)     4128        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 32)     128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 32)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 32)     9248        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 32)     128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 32)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 128)    4224        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 128)    16512       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 128)    0           conv2d_19[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 128)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4, 4, 128)    512         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 4, 128)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 4, 4, 32)     4128        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 4, 4, 32)     128         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 4, 4, 32)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 4, 4, 32)     9248        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 4, 4, 32)     128         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 4, 4, 32)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 4, 4, 128)    4224        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 4, 4, 128)    16512       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 4, 128)    0           conv2d_27[0][0]                  \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 4, 4, 128)    512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 4, 4, 128)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 128)    512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 4, 4, 32)     4128        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 128)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 4, 4, 32)     128         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 32)     4128        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 4, 4, 32)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 32)     128         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 4, 4, 32)     9248        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 32)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 4, 4, 32)     128         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 32)     9248        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 4, 4, 32)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 32)     128         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 4, 4, 128)    4224        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 4, 4, 128)    16512       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 32)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 4, 4, 128)    0           conv2d_31[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 128)    4224        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 128)    16512       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 8, 128)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 128)    0           conv2d_23[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 128)    0           up_sampling2d[0][0]              \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 8, 8, 128)    512         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 8, 8, 128)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 32)     4128        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 32)     128         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 32)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 32)     9248        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 128)  512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 32)     128         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 32)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 32)   4128        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 128)    4224        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 128)    16512       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 128)    0           conv2d_35[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 128)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 128)  16512       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 128)  16512       conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 128)  0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 128)  4224        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 128)  16512       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 16, 16, 128)  0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 128)  0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 16, 16, 128)  0           lambda[0][0]                     \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 128)  512         multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 32)   4128        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 32)   128         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 32)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 32)   9248        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 32)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 128)  4224        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 128)  16512       multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 128)  0           conv2d_41[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 128)  512         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 128)  16512       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 128)  512         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 128)    147584      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 128)    512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 128)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 256)    33024       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 256)    33024       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 256)    0           conv2d_45[0][0]                  \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 256)    1024        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 256)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 64)     16448       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 64)     256         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 64)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 8, 8, 64)     36928       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 64)     256         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 64)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 8, 8, 256)    16640       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 8, 8, 256)    65792       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 256)    0           conv2d_49[0][0]                  \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 256)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 4, 4, 256)    1024        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 256)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 4, 4, 64)     16448       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 4, 4, 64)     256         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 4, 4, 64)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 4, 4, 64)     36928       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 4, 4, 64)     256         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 64)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 4, 4, 256)    16640       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 4, 4, 256)    65792       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 4, 256)    0           conv2d_61[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 256)    1024        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 256)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 4, 4, 64)     16448       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 64)     256         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 64)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 4, 4, 64)     36928       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 8, 8, 256)    1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 64)     256         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 256)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 64)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 64)     16448       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 4, 4, 256)    16640       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 4, 4, 256)    65792       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 64)     256         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 4, 4, 256)    0           conv2d_65[0][0]                  \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 64)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 8, 8, 256)    0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 64)     36928       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 256)    65792       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 64)     256         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 256)    65792       conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 64)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 256)    0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 256)    16640       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 256)    65792       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 8, 8, 256)    0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 256)    0           conv2d_57[0][0]                  \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 8, 8, 256)    0           lambda_1[0][0]                   \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 8, 8, 256)    1024        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 256)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 64)     16448       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 64)     256         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 64)     36928       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 64)     256         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 64)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 256)    16640       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 256)    65792       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 8, 8, 256)    0           conv2d_71[0][0]                  \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 256)    1024        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 256)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 256)    65792       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 256)    1024        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 256)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 4, 4, 256)    590080      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 4, 4, 256)    1024        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 4, 4, 256)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 4, 4, 512)    131584      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 4, 4, 512)    131584      add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 4, 4, 512)    0           conv2d_75[0][0]                  \n",
      "                                                                 conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 4, 4, 512)    2048        add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 4, 4, 512)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 4, 4, 128)    65664       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 4, 4, 128)    512         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 4, 4, 128)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 4, 4, 128)    147584      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 4, 4, 128)    512         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 4, 4, 128)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 4, 4, 512)    66048       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 4, 4, 512)    262656      add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 4, 4, 512)    0           conv2d_79[0][0]                  \n",
      "                                                                 conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 2, 2, 512)    0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 2, 2, 512)    2048        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 2, 2, 512)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 2, 2, 128)    65664       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 2, 2, 128)    512         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 2, 2, 128)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 2, 2, 128)    147584      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 2, 2, 128)    512         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 2, 2, 128)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 2, 2, 512)    66048       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 2, 2, 512)    262656      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 2, 2, 512)    0           conv2d_91[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 2, 2, 512)    2048        add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 2, 2, 512)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 2, 2, 128)    65664       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 2, 2, 128)    512         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 2, 2, 128)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 2, 2, 128)    147584      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 4, 4, 512)    2048        add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 2, 2, 128)    512         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 4, 4, 512)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 2, 2, 128)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 4, 4, 128)    65664       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 2, 2, 512)    66048       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 2, 2, 512)    262656      add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 4, 4, 128)    512         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 2, 2, 512)    0           conv2d_95[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 4, 4, 128)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 4, 4, 512)    0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 4, 4, 128)    147584      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 4, 4, 512)    262656      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 4, 4, 128)    512         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 4, 4, 512)    262656      conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 4, 4, 128)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 4, 4, 512)    0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 4, 4, 512)    66048       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 4, 4, 512)    262656      add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 4, 4, 512)    0           activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 4, 4, 512)    0           conv2d_87[0][0]                  \n",
      "                                                                 conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 4, 4, 512)    0           lambda_2[0][0]                   \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 4, 4, 512)    2048        multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 4, 4, 512)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 4, 4, 128)    65664       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 4, 4, 128)    512         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 4, 4, 128)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 4, 4, 128)    147584      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 4, 4, 128)    512         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 4, 4, 128)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 4, 4, 512)    66048       activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 4, 4, 512)    262656      multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 4, 4, 512)    0           conv2d_101[0][0]                 \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 4, 4, 512)    2048        add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 4, 4, 512)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 4, 4, 512)    262656      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 4, 4, 512)    2048        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 4, 4, 512)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 4, 4, 512)    2359808     activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 4, 4, 512)    2048        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 4, 4, 512)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 4, 4, 1024)   525312      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 4, 4, 1024)   525312      add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 4, 4, 1024)   0           conv2d_105[0][0]                 \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 4, 4, 1024)   4096        add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 4, 4, 1024)   1049600     activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 4, 4, 1024)   4096        conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 4, 4, 1024)   9438208     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 4, 4, 1024)   4096        conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 4, 4, 1024)   1049600     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 4, 4, 1024)   1049600     add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 4, 4, 1024)   0           conv2d_109[0][0]                 \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 4, 4, 1024)   4096        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 4, 4, 1024)   1049600     activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 4, 4, 1024)   4096        conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 4, 4, 1024)   9438208     activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 4, 4, 1024)   4096        conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 4, 4, 1024)   1049600     activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 4, 4, 1024)   1049600     add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 4, 4, 1024)   0           conv2d_113[0][0]                 \n",
      "                                                                 conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 1024)   0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           10250       dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 34,444,362\n",
      "Trainable params: 34,411,850\n",
      "Non-trainable params: 32,512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a model\n",
    "model = AttentionResNet56_mini(shape=(32,32,3), in_channel=32, kernel_size=5, skip=2, n_classes=10, dropout=0.3, regularization=0.01)\n",
    "\n",
    "# prepare usefull callbacks\n",
    "# lr_reducer = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=7, min_lr=10e-7, epsilon=0.01, verbose=1)\n",
    "# early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, patience=15, verbose=1)\n",
    "# callbacks= [lr_reducer, early_stopper]\n",
    "\n",
    "# define loss, metrics, optimizer\n",
    "model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "39/39 [==============================] - 362s 9s/step - loss: 4.3935 - accuracy: 0.2040 - val_loss: 2.4122 - val_accuracy: 0.1663\n",
      "Epoch 2/15\n",
      "39/39 [==============================] - 365s 9s/step - loss: 2.4442 - accuracy: 0.2890 - val_loss: 2.4459 - val_accuracy: 0.1942\n",
      "Epoch 3/15\n",
      "39/39 [==============================] - 365s 9s/step - loss: 2.2615 - accuracy: 0.3239 - val_loss: 2.7160 - val_accuracy: 0.1663\n",
      "Epoch 4/15\n",
      "39/39 [==============================] - 365s 9s/step - loss: 2.1815 - accuracy: 0.3264 - val_loss: 2.6212 - val_accuracy: 0.1797\n",
      "Epoch 5/15\n",
      "39/39 [==============================] - 373s 10s/step - loss: 2.0400 - accuracy: 0.3526 - val_loss: 2.9135 - val_accuracy: 0.1473\n",
      "Epoch 6/15\n",
      "39/39 [==============================] - 359s 9s/step - loss: 1.9975 - accuracy: 0.3664 - val_loss: 2.6609 - val_accuracy: 0.2221\n",
      "Epoch 7/15\n",
      "39/39 [==============================] - 368s 9s/step - loss: 2.1231 - accuracy: 0.3543 - val_loss: 2.4764 - val_accuracy: 0.2500\n",
      "Epoch 8/15\n",
      "39/39 [==============================] - 365s 9s/step - loss: 1.9214 - accuracy: 0.3927 - val_loss: 2.3344 - val_accuracy: 0.2857\n",
      "Epoch 9/15\n",
      "39/39 [==============================] - 381s 10s/step - loss: 1.9466 - accuracy: 0.3900 - val_loss: 2.0194 - val_accuracy: 0.3806\n",
      "Epoch 10/15\n",
      "39/39 [==============================] - 381s 10s/step - loss: 1.8769 - accuracy: 0.4140 - val_loss: 2.3402 - val_accuracy: 0.2958\n",
      "Epoch 11/15\n",
      "39/39 [==============================] - 370s 9s/step - loss: 1.8782 - accuracy: 0.4095 - val_loss: 1.8959 - val_accuracy: 0.4096\n",
      "Epoch 12/15\n",
      "39/39 [==============================] - 377s 10s/step - loss: 1.8151 - accuracy: 0.4247 - val_loss: 1.8176 - val_accuracy: 0.4431\n",
      "Epoch 13/15\n",
      "39/39 [==============================] - 372s 10s/step - loss: 1.7851 - accuracy: 0.4370 - val_loss: 1.9009 - val_accuracy: 0.4263\n",
      "Epoch 14/15\n",
      "39/39 [==============================] - 383s 10s/step - loss: 1.7414 - accuracy: 0.4437 - val_loss: 1.6508 - val_accuracy: 0.4676\n",
      "Epoch 15/15\n",
      "39/39 [==============================] - 385s 10s/step - loss: 1.7739 - accuracy: 0.4319 - val_loss: 1.7281 - val_accuracy: 0.4520\n",
      "Time taken by above cell is 92.88277765512467.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epc = 15\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "step_size_train = train_generator.n // train_generator.batch_size\n",
    "test_generator = val_datagen.flow(x_test, y_test, batch_size=batch_size)\n",
    "step_size_test = test_generator.n // test_generator.batch_size\n",
    "\n",
    "log_dir='logs/'.format(int(time.time()))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = step_size_train,\n",
    "                    epochs = epc, workers = 4,\n",
    "                    validation_data = test_generator,\n",
    "                    validation_steps = step_size_test,\n",
    "                    callbacks=[tensorboard_callback])\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format((end-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 800ms/step - loss: 1.7281 - accuracy: 0.4520\n",
      "Test loss: 1.7281078440802438\n",
      "Test accuracy: 0.45200893\n"
     ]
    }
   ],
   "source": [
    "# model.evaluate_generator(val_datagen.flow(x_test, y_test), steps=len(x_test)/128, use_multiprocessing=True)\n",
    "\n",
    "scores = model.evaluate(test_generator, steps=step_size_test)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Model_15eps.h5')\n",
    "# tf.keras.models.load_model('Model_15eps.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zhaoyang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 200\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "subtract_pixel_mean = True\n",
    "# Load the CIFAR10 data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "\n",
    "\n",
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        zca_epsilon=1e-06,\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,\n",
    "        zoom_range=0.,\n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=4,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
